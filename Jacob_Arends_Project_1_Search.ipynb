{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jacob Arends Project 1 - Search.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "65F-jXa1BjUx"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jarends101/cis490/blob/main/Jacob_Arends_Project_1_Search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project 1 - __*SEARCH*__ (150 pts total)\n",
        "\n",
        "<font color=\"red\">__*PLEASE:* YOU MUST WRITE YOUR OWN CODE, YOU MAY NOT SHARE CODE, YOU CAN DISCUSS WITH EACH OTHER, YOU CAN USE ANY RESOURCE ON THE INTERNET__</font>‚ùó\n",
        "\n",
        "<img src=\"https://img.freepik.com/free-vector/black-robot-holding-magnifying-glass-data-search-artificial-intelligence_48369-37442.jpg?size=338&ext=jpg\" width=200>\n",
        "\n",
        "Trying to find an optimal strategy for an agent can be viewed as a search through a [**space**](https://www.youtube.com/watch?v=BVn1oQL9sWg&t=44s) of possible solutions. For example, one type of open loop solution in MountainCar\n",
        "that we discussed, involved:\n",
        "\n",
        "  * First going left (i.e. reverse or action = 0) for a fixed number of steps (*num_left*).\n",
        "  * Then, going right (action = 2) until done\n",
        "\n",
        "The search space in this case becomes a one dimensional search for the ideal number of left steps to take (**num_left**) before going right. In other words, the problem is: find the *optimal* **num_left**, where optimal means it gets the car to the flag in the lowest number of steps on average.  \n",
        "\n",
        "Because the MountainCar environment has a random element (i.e. the car starts in a slightly random position near the bottom of the hill), we would need to test each option of **num_left** several times in order to calculate an average. In problems where a large number of steps can be easily done, we can simply use a **brute force** - style of search, i.e. try every possible solution to find the best.\n",
        "\n",
        "When the problem is such that it is too computationally intensive to perform a brute force search in a reasonable amount of time, we can use a variety of **local search** algorithms. **local search** refers generally to the concept that you evaluate a single point in the solution space, (the first point is usually random, lets call it Solution zero, or $S_0$), then take a next step to a new spot in the solution space (lets call it $S_1$) that is *fairly* close (i.e. local) to the spot you were just at. By *evaluate* we mean calculate or estimate some cost or benefit. For MountainCar, the cost is the number of steps (i.e. delay) that it takes for the car to reach the flag. For some problems, there is a direct formula for evaluating the cost as well as the slope of the cost with respect to one of the variables. There is no such formula for MountainCar, we are at the mercy of running the simulation environment serveral times to evaluate the average delay for a givein solution, and have no direct way to calcuate how muuch the delay will go down or up if we increase or decreate the number of left steps from a solution we just evaluated. In these types of problems, we typically use **randomized local search**, that is, sthe next step we take in searching the solution space ($S_{t+1}$, where t is time, t+1 is the next step) is to take a random step in a random direction. If the new solution space spot $S+{t+1}$ is better than the last $S_t$, we continue along this \"path\", and take the next next random step $S_{t+2}$ a random step away from $S_{t+1}$. If the new spot $S_{t+1}$ is worse than $S_t$, we \"go back\" to $S_t$ and try a new random step $S_{t+1'}$ (note the prime)in the solution space. **hill climbing** is the general term for accepting a new step if it is better than the last. \n",
        "\n",
        "One particularly intersting randomized local search technique is analogized with the process of *annealing metal*, i.e heating up metal and slowly cooling it down to encourage a *lower-energy, more-stable state* in which crystallization with a low number of deformtities is encouraged. In **simulated annealing**, we modify hill climbing such that, if the next solution $S_{t+1}$ evaluated is worse than the last $S_{t}$, we flip a loaded coin to decide if we accept the worse solution $S_{t+1}$ and continue the search from there, or go back to the previous better solution $S_{t}$.\n",
        "\n",
        "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS1L50SeRkXL_rL21NWTQ_yTP1reDLi5okSnkGag_aO4umzpMfdck9mnpGNKngswXz-udc&usqp=CAU\">"
      ],
      "metadata": {
        "id": "dNSc4S5MZp1G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Part I QUESTIONS (50 pts)\n",
        "\n",
        "For each, please give a one sentence answer.\n",
        "\n",
        "**What are the differences from breadth-first search and depth-first search?** Depth first search expands on the deepest path first, while breadth-first will go to all the nodes before going to the child nodes.\n",
        "\n",
        "**What is brute force search?** Brute force is trying all available options until the best solution is found, long time to execute.  \n",
        "\n",
        "**What is hill climbing?**  Hill climbing is a local search that finds the solution by changing the values by a small amount and accepting that value if it was better than the previous until the agent arrives at the best solution.\n",
        "\n",
        "**What is beam search?**  It searches for the best score through promising nodes, limits the search, saves memory, \"good enough\". \n"
      ],
      "metadata": {
        "id": "65F-jXa1BjUx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Part II - Brute force search of 1d in Mountain Car (25pts)::\n",
        "\n"
      ],
      "metadata": {
        "id": "sGUvilz2WUW7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "yXv6kHBxWPRF",
        "outputId": "ea0ea775-26a6-4a6e-ffd8-ac39d3809fa4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# brute force search of one type of MountainCar agent: an\n",
        "# agent that goes a number of lefts first, then right until done\n",
        "import gym\n",
        "import matplotlib.pyplot as plt  # This import is for plotting (2d graph)\n",
        "\n",
        "num_repeats = 1000  # The number of times gym env is run for each search point\n",
        "search_space = list(range(25,50))  # All potential #lefts before going right\n",
        "avg_score_list = [] \n",
        "\n",
        "env = gym.make(\"MountainCar-v0\")\n",
        "\n",
        "for num_lefts in search_space:\n",
        "  #print('#lefts = ', num_lefts, end='')\n",
        "  result_list = []\n",
        "  for iteration in range(num_repeats):\n",
        "    observation = env.reset()\n",
        "    step_i = 0  # use this variable as a counter for each step taken\n",
        "    while True:    \n",
        "      if step_i < num_lefts:\n",
        "        action = 0\n",
        "      else:\n",
        "        action = 2\n",
        "      observation, reward, done, info = env.step(action) \n",
        "      step_i = step_i + 1\n",
        "\n",
        "      # if car reaches the flag, exit the loop\n",
        "      if done: \n",
        "        break;\n",
        "    result_list.append(step_i)\n",
        "  score = sum(result_list)/num_repeats\n",
        "  #print(', avg score=', score)\n",
        "  avg_score_list.append(score)\n",
        "env.close()\n",
        "\n",
        "# The following code is for making a plot of score vs. # lefts\n",
        "plt.plot(search_space, avg_score_list)\n",
        "plt.xlabel('Search Space (# lefts taken before going right)')\n",
        "plt.ylabel('avg # steps until done')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Explain what is going on in the figure above. Be sure to answer:\n",
        "  * What is the program doing generally?\n",
        "    * **Answer**: The program is defining the amount of steps it takes to get to the top of the hill.  Specifically, it's defining the amount of steps left it should take first.  The agent repeats each step 10 times before it goes to the next step.\n",
        "  * Why does it look so noisy?\n",
        "    * **Answer**: The initial starting location of the car is changing each time the program is ran.  This with the fact that the agent only repeated 10 times made it hard to get a consistent answer. \n",
        "  * How can you make it look less noisy?\n",
        "    * **Answer**: Define the position the car starts at.  If we get it to start at a consistent spot that will help with the volatility.  Also repeating it more times will help get a more consistent number.\n",
        "  * How can you speed up the evaluation?\n",
        "    * **Answer**: The best thing to do is narrow the search, instead of looking at all the steps like 0-200. We can look at steps 10-50 for example.  If we want the agent to do a different search method that could also potentially speed up the evaluation as well.\n",
        "\n",
        "1. Modify the code in the cell above so that it uses 1000 repeats at each search point (i.e. each value for num_lefts), and limits the search to the range of only 25 to 50 num_lefts.  \n",
        "\n",
        "1. Rerun the code with your changes and answer the following:\n",
        "  * What did you learn from the modifications?\n",
        "    * **Answer**: Narrow the search space to allow for more searches in the space, since you aren't wasting time looking at other steps.  The search space is no longer being brute forced by looking at all the steps. \n",
        "  * What were the benefits and disadvantages of your changes?\n",
        "    * **Answer**: It takes more time because each step is being ran 1000 times, which can take a while, compared to the 10 repeats. \n",
        "      * Benefits: More accurate answer (less noise).  Readablitily, graph easier to read, a more clear conculsion can be made.\n",
        "      * Disadvantages: Took a while for the program to run, since the search was widen with the repeats being increased. \n",
        "  * Do you think its possible to find a better **agent** (i.e. not a better search method)? If so, how does it operate?\n",
        "    * **Answer**: Something like q learning might help here (if that's a different agent...).  Each evolution of the game the agent can idenitfy where the starting position is and eventually take the appropriate amount of steps left to reach its goal. \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5M_haolEnpRZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Part III - Hill-climbing (25pts)**\n",
        "\n",
        "The following cell performs a randomized local search of the num_left space for agents of the type that go left for num_lefts and then go right until done. Think of each value of num_lefts as a point in the search space.\n",
        "\n",
        "####**Picking the next search point**\n",
        "The code randomly selects between either +1 and -1 for the next spot to evaluate. For example, if the code just finished evaluating num_lefts = 20, the next value of num_lefts to evaluate will be randomly picked between 19 and 21.\n",
        "\n",
        "####**Deciding whether to use the next search point**\n",
        "If the next search point results in a better (lower) score, the search will continue from the next point. If it is not better, the code will \"go back\" to the last value of num_lefts and try to randomly pick a search point again.\n",
        "\n",
        "####**Deciding when to stop**\n",
        "If the last 5 attempts of picking a next search point fail (i.e. result in a lower score than the current point), the search will stop.\n",
        "\n",
        "1. Modify the code below so that the search point is randomly selected from +3, +2, +1, -1, -2, or -3 from the current point. Run the code after the change. \n",
        "\n",
        "1. Modfiy the code so that instead of always rejecting a new point that results in a worse, you unstead flip a coin, and 50% of the time, accept it as the next new point. Run the code after this change.\n",
        "\n",
        "1. Answer the following questions:  \n",
        "  * **How does the performance of each version of code compare? Is it what you expect?**\n",
        "  \n",
        "    The first change with randomly selecting +3 through -3 worked as expected, each test point was different and within the range set.  The coin flip also worked as expected with not always rejecting a new point if worse.  With this the performance was different compared to the original code.  The changes defined a much better local search conclusion compared to the original.\n",
        "  * **In search problems, there is often a tradeoff of chances of finding a better/best solution vs. the amount of time you spend (yielding yet another type of optimization problem of optimizing bang for buck of computing. Which parameters or techniques can you adjust to adjust this bang for buck?**\n",
        "\n",
        "    The amount of times a step is repeated or the search space can all be changed.  "
      ],
      "metadata": {
        "id": "l774ib_mcF0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import matplotlib.pyplot as plt  # This import is for plotting\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def pick_next_point(current_point):\n",
        "  deltas = [-3,-2,-1,1,2,3]\n",
        "  next_point = current_point + random.choice(deltas)\n",
        "  if next_point < 25:\n",
        "    next_point = 25\n",
        "  if next_point > 55:\n",
        "    next_point = 55\n",
        "  return next_point\n",
        "\n",
        "def eval_point(num_lefts, num_repeats, env):\n",
        "  \"\"\"Evaluates and returns the average delay until done when using num_lefts. \n",
        "  \"\"\"\n",
        "  result_list = []\n",
        "  for iteration in range(num_repeats):\n",
        "    observation = env.reset()\n",
        "    step_i = 0  # use this variable as a counter for each step taken\n",
        "    while True:    \n",
        "      if step_i < num_lefts:\n",
        "        action = 0\n",
        "      else:\n",
        "        action = 2\n",
        "      observation, reward, done, info = env.step(action) \n",
        "      step_i = step_i + 1\n",
        "\n",
        "      # if car reaches the flag, exit the loop\n",
        "      if done: \n",
        "        break;\n",
        "    result_list.append(step_i)\n",
        "\n",
        "  score = sum(result_list)/num_repeats\n",
        "  return score\n",
        "\n",
        "\n",
        "#---------------------------------------\n",
        "avg_score_list = [] \n",
        "\n",
        "env = gym.make(\"MountainCar-v0\")\n",
        "\n",
        "# randomly pick an starting value for num_lefts\n",
        "num_lefts = int(random.random()*100)\n",
        "search_complete = False\n",
        "num_repeats_for_eval = 50\n",
        "max_search_iter = 100\n",
        "score = eval_point(num_lefts, num_repeats_for_eval, env)\n",
        "\n",
        "search_i = 0\n",
        "while not search_complete:\n",
        "  #pick next point\n",
        "  last_num_lefts = num_lefts\n",
        "  last_score = score\n",
        "  num_lefts = pick_next_point(num_lefts)\n",
        "  print('search iter#', search_i, end='')\n",
        "  print('  current #lefts = ', num_lefts)\n",
        "\n",
        "  #evaluate this point\n",
        "  score = eval_point(num_lefts, num_repeats_for_eval, env)\n",
        "  print(', avg score=', score)\n",
        "  avg_score_list.append([num_lefts, score])\n",
        "  \n",
        "  #acceptance or rejection\n",
        "  if (score > last_score):\n",
        "    #if new point is worse than last point, go back\n",
        "    if random.choice((0,1)):\n",
        "      print('accepted')\n",
        "      num_lefts = last_num_lefts\n",
        "\n",
        "\n",
        "  # evaluate if it is time to stop\n",
        "  search_i += 1\n",
        "  if search_i >= max_search_iter:\n",
        "    search_complete = True\n",
        "env.close()\n",
        "\n",
        "print(avg_score_list)\n",
        "avg_score = np.array(avg_score_list)\n",
        "# The following code is for making a plot of score vs. # lefts\n",
        "plt.scatter(avg_score[:,0], avg_score[:,1])\n",
        "plt.xlabel('Search Space (# lefts taken before going right)')\n",
        "plt.ylabel('avg # steps until done')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Zh5nOsVjntEW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "06206f12-644f-47b3-d277-bf4d7edda045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "search iter# 0  current #lefts =  25\n",
            ", avg score= 188.56\n",
            "search iter# 1  current #lefts =  25\n",
            ", avg score= 190.3\n",
            "accepted\n",
            "search iter# 2  current #lefts =  28\n",
            ", avg score= 183.04\n",
            "search iter# 3  current #lefts =  29\n",
            ", avg score= 166.02\n",
            "search iter# 4  current #lefts =  27\n",
            ", avg score= 173.84\n",
            "accepted\n",
            "search iter# 5  current #lefts =  32\n",
            ", avg score= 157.74\n",
            "search iter# 6  current #lefts =  33\n",
            ", avg score= 168.5\n",
            "accepted\n",
            "search iter# 7  current #lefts =  35\n",
            ", avg score= 159.14\n",
            "search iter# 8  current #lefts =  34\n",
            ", avg score= 144.98\n",
            "search iter# 9  current #lefts =  37\n",
            ", avg score= 164.7\n",
            "accepted\n",
            "search iter# 10  current #lefts =  33\n",
            ", avg score= 179.14\n",
            "accepted\n",
            "search iter# 11  current #lefts =  32\n",
            ", avg score= 166.06\n",
            "search iter# 12  current #lefts =  29\n",
            ", avg score= 176.66\n",
            "accepted\n",
            "search iter# 13  current #lefts =  34\n",
            ", avg score= 158.84\n",
            "search iter# 14  current #lefts =  37\n",
            ", avg score= 146.5\n",
            "search iter# 15  current #lefts =  40\n",
            ", avg score= 152.68\n",
            "search iter# 16  current #lefts =  38\n",
            ", avg score= 152.32\n",
            "search iter# 17  current #lefts =  35\n",
            ", avg score= 155.98\n",
            "search iter# 18  current #lefts =  36\n",
            ", avg score= 142.98\n",
            "search iter# 19  current #lefts =  39\n",
            ", avg score= 143.72\n",
            "search iter# 20  current #lefts =  40\n",
            ", avg score= 149.82\n",
            "accepted\n",
            "search iter# 21  current #lefts =  41\n",
            ", avg score= 165.82\n",
            "accepted\n",
            "search iter# 22  current #lefts =  40\n",
            ", avg score= 160.84\n",
            "search iter# 23  current #lefts =  39\n",
            ", avg score= 145.46\n",
            "search iter# 24  current #lefts =  42\n",
            ", avg score= 143.56\n",
            "search iter# 25  current #lefts =  41\n",
            ", avg score= 164.54\n",
            "search iter# 26  current #lefts =  42\n",
            ", avg score= 142.84\n",
            "search iter# 27  current #lefts =  44\n",
            ", avg score= 156.86\n",
            "search iter# 28  current #lefts =  46\n",
            ", avg score= 162.36\n",
            "accepted\n",
            "search iter# 29  current #lefts =  41\n",
            ", avg score= 150.44\n",
            "search iter# 30  current #lefts =  38\n",
            ", avg score= 149.62\n",
            "search iter# 31  current #lefts =  36\n",
            ", avg score= 143.06\n",
            "search iter# 32  current #lefts =  33\n",
            ", avg score= 153.6\n",
            "accepted\n",
            "search iter# 33  current #lefts =  37\n",
            ", avg score= 153.56\n",
            "search iter# 34  current #lefts =  40\n",
            ", avg score= 158.66\n",
            "search iter# 35  current #lefts =  37\n",
            ", avg score= 146.68\n",
            "search iter# 36  current #lefts =  36\n",
            ", avg score= 153.76\n",
            "accepted\n",
            "search iter# 37  current #lefts =  38\n",
            ", avg score= 165.76\n",
            "accepted\n",
            "search iter# 38  current #lefts =  36\n",
            ", avg score= 148.1\n",
            "search iter# 39  current #lefts =  33\n",
            ", avg score= 161.36\n",
            "accepted\n",
            "search iter# 40  current #lefts =  33\n",
            ", avg score= 147.14\n",
            "search iter# 41  current #lefts =  32\n",
            ", avg score= 164.98\n",
            "search iter# 42  current #lefts =  35\n",
            ", avg score= 149.06\n",
            "search iter# 43  current #lefts =  37\n",
            ", avg score= 146.08\n",
            "search iter# 44  current #lefts =  34\n",
            ", avg score= 158.82\n",
            "search iter# 45  current #lefts =  36\n",
            ", avg score= 150.26\n",
            "search iter# 46  current #lefts =  37\n",
            ", avg score= 144.22\n",
            "search iter# 47  current #lefts =  35\n",
            ", avg score= 160.46\n",
            "accepted\n",
            "search iter# 48  current #lefts =  36\n",
            ", avg score= 143.44\n",
            "search iter# 49  current #lefts =  39\n",
            ", avg score= 156.16\n",
            "search iter# 50  current #lefts =  41\n",
            ", avg score= 157.2\n",
            "accepted\n",
            "search iter# 51  current #lefts =  42\n",
            ", avg score= 160.54\n",
            "accepted\n",
            "search iter# 52  current #lefts =  37\n",
            ", avg score= 165.5\n",
            "search iter# 53  current #lefts =  35\n",
            ", avg score= 136.8\n",
            "search iter# 54  current #lefts =  34\n",
            ", avg score= 152.82\n",
            "search iter# 55  current #lefts =  33\n",
            ", avg score= 162.68\n",
            "accepted\n",
            "search iter# 56  current #lefts =  37\n",
            ", avg score= 157.22\n",
            "search iter# 57  current #lefts =  40\n",
            ", avg score= 150.46\n",
            "search iter# 58  current #lefts =  37\n",
            ", avg score= 151.94\n",
            "accepted\n",
            "search iter# 59  current #lefts =  41\n",
            ", avg score= 146.32\n",
            "search iter# 60  current #lefts =  44\n",
            ", avg score= 160.28\n",
            "search iter# 61  current #lefts =  42\n",
            ", avg score= 164.38\n",
            "search iter# 62  current #lefts =  41\n",
            ", avg score= 147.46\n",
            "search iter# 63  current #lefts =  43\n",
            ", avg score= 159.86\n",
            "search iter# 64  current #lefts =  42\n",
            ", avg score= 158.8\n",
            "search iter# 65  current #lefts =  45\n",
            ", avg score= 171.1\n",
            "search iter# 66  current #lefts =  48\n",
            ", avg score= 174.08\n",
            "search iter# 67  current #lefts =  46\n",
            ", avg score= 171.2\n",
            "search iter# 68  current #lefts =  45\n",
            ", avg score= 162.9\n",
            "search iter# 69  current #lefts =  46\n",
            ", avg score= 165.62\n",
            "search iter# 70  current #lefts =  47\n",
            ", avg score= 160.4\n",
            "search iter# 71  current #lefts =  48\n",
            ", avg score= 162.98\n",
            "search iter# 72  current #lefts =  46\n",
            ", avg score= 162.44\n",
            "search iter# 73  current #lefts =  43\n",
            ", avg score= 155.68\n",
            "search iter# 74  current #lefts =  42\n",
            ", avg score= 155.3\n",
            "search iter# 75  current #lefts =  45\n",
            ", avg score= 150.64\n",
            "search iter# 76  current #lefts =  43\n",
            ", avg score= 145.32\n",
            "search iter# 77  current #lefts =  41\n",
            ", avg score= 155.5\n",
            "accepted\n",
            "search iter# 78  current #lefts =  46\n",
            ", avg score= 161.86\n",
            "search iter# 79  current #lefts =  43\n",
            ", avg score= 160.34\n",
            "search iter# 80  current #lefts =  42\n",
            ", avg score= 154.14\n",
            "search iter# 81  current #lefts =  40\n",
            ", avg score= 168.96\n",
            "accepted\n",
            "search iter# 82  current #lefts =  39\n",
            ", avg score= 153.18\n",
            "search iter# 83  current #lefts =  40\n",
            ", avg score= 159.54\n",
            "search iter# 84  current #lefts =  42\n",
            ", avg score= 147.56\n",
            "search iter# 85  current #lefts =  44\n",
            ", avg score= 171.74\n",
            "accepted\n",
            "search iter# 86  current #lefts =  41\n",
            ", avg score= 155.2\n",
            "search iter# 87  current #lefts =  43\n",
            ", avg score= 164.86\n",
            "search iter# 88  current #lefts =  44\n",
            ", avg score= 161.76\n",
            "search iter# 89  current #lefts =  46\n",
            ", avg score= 167.54\n",
            "search iter# 90  current #lefts =  49\n",
            ", avg score= 165.1\n",
            "search iter# 91  current #lefts =  48\n",
            ", avg score= 172.18\n",
            "accepted\n",
            "search iter# 92  current #lefts =  50\n",
            ", avg score= 164.44\n",
            "search iter# 93  current #lefts =  53\n",
            ", avg score= 182.56\n",
            "search iter# 94  current #lefts =  52\n",
            ", avg score= 181.5\n",
            "search iter# 95  current #lefts =  49\n",
            ", avg score= 169.24\n",
            "search iter# 96  current #lefts =  48\n",
            ", avg score= 175.9\n",
            "accepted\n",
            "search iter# 97  current #lefts =  46\n",
            ", avg score= 173.36\n",
            "search iter# 98  current #lefts =  48\n",
            ", avg score= 175.56\n",
            "search iter# 99  current #lefts =  45\n",
            ", avg score= 161.48\n",
            "[[25, 188.56], [25, 190.3], [28, 183.04], [29, 166.02], [27, 173.84], [32, 157.74], [33, 168.5], [35, 159.14], [34, 144.98], [37, 164.7], [33, 179.14], [32, 166.06], [29, 176.66], [34, 158.84], [37, 146.5], [40, 152.68], [38, 152.32], [35, 155.98], [36, 142.98], [39, 143.72], [40, 149.82], [41, 165.82], [40, 160.84], [39, 145.46], [42, 143.56], [41, 164.54], [42, 142.84], [44, 156.86], [46, 162.36], [41, 150.44], [38, 149.62], [36, 143.06], [33, 153.6], [37, 153.56], [40, 158.66], [37, 146.68], [36, 153.76], [38, 165.76], [36, 148.1], [33, 161.36], [33, 147.14], [32, 164.98], [35, 149.06], [37, 146.08], [34, 158.82], [36, 150.26], [37, 144.22], [35, 160.46], [36, 143.44], [39, 156.16], [41, 157.2], [42, 160.54], [37, 165.5], [35, 136.8], [34, 152.82], [33, 162.68], [37, 157.22], [40, 150.46], [37, 151.94], [41, 146.32], [44, 160.28], [42, 164.38], [41, 147.46], [43, 159.86], [42, 158.8], [45, 171.1], [48, 174.08], [46, 171.2], [45, 162.9], [46, 165.62], [47, 160.4], [48, 162.98], [46, 162.44], [43, 155.68], [42, 155.3], [45, 150.64], [43, 145.32], [41, 155.5], [46, 161.86], [43, 160.34], [42, 154.14], [40, 168.96], [39, 153.18], [40, 159.54], [42, 147.56], [44, 171.74], [41, 155.2], [43, 164.86], [44, 161.76], [46, 167.54], [49, 165.1], [48, 172.18], [50, 164.44], [53, 182.56], [52, 181.5], [49, 169.24], [48, 175.9], [46, 173.36], [48, 175.56], [45, 161.48]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "y8-6Z2HXqItZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Search - Steepest decent/Hill-climbing"
      ],
      "metadata": {
        "id": "La4_AMNRYq1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Part IV - Adversarial Search (50pts)##\n",
        "\n",
        "An **adversarial search** is a search in a game in which there are multiple adversaries, such as tic tac toe, chess, backgammon, go, as well as games with more than two opponents, such as chinese checkers or risk.\n",
        "\n",
        "The **MiniMax Strategy** (aka MinMax and MaxiMin)\n",
        "is a agent and search strategy used not only in AI, but also game theory, which assumes the opponent will play a perfect next move, so the agent should play the next move which minimizes the opponent's best possible outcome. In other words, when it is the agent's turn, it must search ahead at least the next two moves, and pick the move that gives the opponent the worst best option. (Please take a moment to think about that and make sure you understand).\n",
        "\n",
        "\n",
        "###Tic Tac Toe\"\n",
        "\n",
        "\n",
        "1. (0pts) Run the code to see how the random_agent performs. Be sure to read the random_agent function and understand it.\n",
        "2. (25 pts) Finish implementing the function agent1, the look ahead 1 move agent. Take note of the performance provided by the eval functions.\n",
        "3. (25 pts) Finish implememting the function agent2, the look ahead by 2 minimax strategy. \n",
        "\n",
        "If you can't get the code working, provide an explanation of how you expect it should work and what you expect the results to be. If you get it working (and it is right, you get full credit). However, if there is a bug, in order to maximize your chances of partial credit, you can also add an explanation of how you think it should work and whether the results are what you expect."
      ],
      "metadata": {
        "id": "BMFisoMzYfL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This code implements the TIC TAC TOE engine as well as a random_agent,\n",
        "# and code to run it over and over in order to evaluate it. You don't have to \n",
        "# read and understand all the code, but you should at least read the function\n",
        "# names, arguments, and each function's \"\"\" \"\"\" comments.\n",
        "import random\n",
        "\n",
        "# the 3-in-a-row cell combinations that result in a win\n",
        "WINS = ((0,1,2),(3,4,5),(6,7,8),(0,3,6),(1,4,7),(2,5,8),(0,4,8),(2,4,6))\n",
        "\n",
        "def valid_next_moves(board):\n",
        "  \"\"\"Returns a list of valid next moves given the board_state. \n",
        "  - Cells are referred by their 0-8 index (i.e. not 1-9). For example\n",
        "  - if the board is empty, it will return [0,1,2,3,4,5,6,7,8]. \"\"\"\n",
        "  moves_list = []\n",
        "  # cycle through all the cells. If it is empty, add i to moves_list\n",
        "  for i in range(9):\n",
        "    if board[i] == '-':\n",
        "      moves_list.append(i)\n",
        "  return moves_list\n",
        "\n",
        "def get_x_cells(board):\n",
        "  \"\"\"Returns a list of cells that have X's in them.\"\"\"\n",
        "  return [i for i,v in enumerate(board) if v=='X']\n",
        "\n",
        "def get_o_cells(board):\n",
        "  \"\"\"Returns a list of cells that have O's in them.\"\"\"\n",
        "  return [i for i,v in enumerate(board) if v=='O']\n",
        "  \n",
        "def is_x_winner(board):\n",
        "  \"\"\"Returns True if there are three X's in a row, otherwise False\"\"\"\n",
        "  x_cells = get_x_cells(board)\n",
        "  \n",
        "  for win in WINS:\n",
        "    if len(set(win) & set(x_cells)) == 3:\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "def is_o_winner(board):\n",
        "  \"\"\"Returns True if there are three O's in a row, otherwise False\"\"\"\n",
        "  o_cells = get_o_cells(board)\n",
        "  \n",
        "  for win in WINS:\n",
        "    if len(set(win) & set(o_cells)) == 3:\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "def is_game_over(board):\n",
        "  \"\"\" Returns 'X' if X won; 'O' if O won; 'CAT' if Cat's game, otherwise False. \n",
        "  \"\"\"\n",
        "  if is_x_winner(board):\n",
        "    return 'X'\n",
        "  elif is_o_winner(board):\n",
        "    return 'O'\n",
        "  elif valid_next_moves(board) == []:\n",
        "    return \"CAT\"\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def random_agent(board):\n",
        "  \"\"\" Returns a random move out of valid next moves.\n",
        "  If no moves are left, produces an assertion error \"\"\"\n",
        "  moves = valid_next_moves(board)\n",
        "  if moves == []:\n",
        "    assert(False)\n",
        "  else:\n",
        "    return random.choice(moves)\n",
        "\n",
        "def play(x_agent, o_agent):\n",
        "  \"\"\" Plays one game of tic_tac_toe calling the x_agent on x's turns and the \n",
        "  o_agent on o's turns.\n",
        "  Returns: \n",
        "    (winner, move_history, board_state)\n",
        "  where winner is one of {'X','O','CAT'}, move_history is a list of move\n",
        "  indices as they were played, and board_state is a list of the final board \n",
        "  contents. \n",
        "  \"\"\"\n",
        "  board_state = ['-']*9 # beginning empty board\n",
        "  move_history = []     # this list will keep track of all moves\n",
        "  while not is_game_over(board_state):\n",
        "    if (len(move_history) % 2) == 0:\n",
        "      next_move = x_agent(board_state)\n",
        "      board_state[next_move] = 'X'\n",
        "    else:\n",
        "      next_move = o_agent(board_state)\n",
        "      board_state[next_move] = 'O'\n",
        "    move_history += [next_move]\n",
        "\n",
        "  #You can uncomment any of the print statements to help debug your agent code.\n",
        "  #print('Game Over')\n",
        "  winner = is_game_over(board_state)\n",
        "  #print('Winner is: ', winner)\n",
        "  #print(str(board_state[0:3]))\n",
        "  #print(str(board_state[3:6]))\n",
        "  #print(str(board_state[6:9]))\n",
        "  #print(move_history)\n",
        "  return (winner, move_history, board_state)\n",
        "\n",
        "def eval(x_agent,o_agent):\n",
        "  \"\"\"Runs 100 games with the designated agents and prints the number of wins \n",
        "  for x, o, and cat. \n",
        "  \"\"\"\n",
        "  x_wins, o_wins, cat_wins = 0, 0, 0\n",
        "  for i in range(100):\n",
        "    winner = play(x_agent, o_agent)[0] #the 0th list item returned is the winner\n",
        "    if(winner == 'X'):\n",
        "      x_wins += 1\n",
        "    elif(winner == 'O'):\n",
        "      o_wins += 1\n",
        "    elif(winner == 'CAT'):\n",
        "      cat_wins += 1\n",
        "    else:\n",
        "      assert(False)  # something bad happened if there is no winner\n",
        "  print('wins:')\n",
        "  print(' x:', x_wins) \n",
        "  print(' o:', o_wins)\n",
        "  print(' c:', cat_wins)\n",
        "\n",
        "\n",
        "eval(random_agent, random_agent)"
      ],
      "metadata": {
        "id": "4wibbzgUWtbK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85a74116-6f69-4f43-ba33-7103b186ca9c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wins:\n",
            " x: 58\n",
            " o: 27\n",
            " c: 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: finish implementing agent1, it currently just selects first valid move\n",
        "def agent1(board):\n",
        "  \"\"\"Cycles through all valid moves for the current board. If one results in a \n",
        "  win, it will return that move, otherwise, it will randomly pick a move. \"\"\"\n",
        "  moves = valid_next_moves(board)\n",
        "  if moves == []:\n",
        "    assert(False)\n",
        "\n",
        "  # check to see if it is X's turn or O's turn\n",
        "  if len(moves)%2:\n",
        "    player, opponent = 'X', 'O'\n",
        "    i_am_winner = is_x_winner\n",
        "  else:\n",
        "    player, opponent = 'O', 'X'\n",
        "    i_am_winner = is_o_winner\n",
        "\n",
        "  best_move = moves[0] # temporarily pick first valid move\n",
        "  # TODO: INSERT BELOW!!!\n",
        "  # HINTS: use a for loop, use the function i_am_winner(), use a temporary\n",
        "  # game board with the current move being evaluated added. A copy of the list\n",
        "  # can be made using the list.copy() function:\n",
        "  #   test_board = board.copy()\n",
        "  # When you find a winning move, return it immediately rather than continuing\n",
        "  # looping. \n",
        "  for move in moves:\n",
        "    temp_board = board.copy()\n",
        "    # have player move into cell# move by modifying test_board\n",
        "    temp_board[move] = player\n",
        "    if i_am_winner(temp_board):\n",
        "      return move\n",
        "  # TODO: INSERT ABOVE HERE!!!\n",
        "\n",
        "  return random.choice(moves)\n",
        "  \n",
        "  return best_move\n",
        "\n",
        "\n",
        "eval(agent1, random_agent)\n",
        "eval(random_agent, agent1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlETmRvmMDKy",
        "outputId": "d206ddcf-20e9-4dee-a405-45896328fee3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wins:\n",
            " x: 85\n",
            " o: 8\n",
            " c: 7\n",
            "wins:\n",
            " x: 37\n",
            " o: 54\n",
            " c: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO, finish evaluating agent2, it currently just selects first valid move\n",
        "def agent2(board):\n",
        "  \"\"\"A minimal implementation of minimax strategy looking two moves ahead.\n",
        "  If a next move results in a win, it is returned. Otherwise, for each\n",
        "  player move, it will evaluate if the opponent can win. If there is a move\n",
        "  which doesn't allow the opponent to win, it will be selected.\n",
        "  \"\"\"\n",
        "  moves = valid_next_moves(board)\n",
        "  if moves == []:\n",
        "    assert(False)\n",
        "  if len(moves)%2:\n",
        "    player, opponent = 'X', 'O'\n",
        "    player_is_winner = is_x_winner\n",
        "    opponent_is_winner = is_o_winner\n",
        "  else:\n",
        "    player, opponent = 'O', 'X'\n",
        "    player_is_winner = is_o_winner\n",
        "    opponent_is_winner = is_x_winner\n",
        "\n",
        "  # for each valid move, hold's opponents best score\n",
        "  move_opponent_score_dict = {} \n",
        "\n",
        "  worst_move_for_opponent = moves[0] # temporarily pick first valid move\n",
        "\n",
        "  # TODO: INSERT CODE BELOW (2 for loops)\n",
        "  # HINTS: use a for loop within a for loop. The outer for loop will cycle\n",
        "  # over player moves, the inner for loop cycles over opponent moves possible\n",
        "  # after the current selected player move.\n",
        "  # Only keep track of two types of score for the opponent (1 for opponent win,\n",
        "  # 0 otherwise)\n",
        "  #return move with lowest opponent score\n",
        "  for i in moves:\n",
        "    temp_board = board.copy()\n",
        "    # have player move into cell# move by modifying test_board\n",
        "    temp_board[i] = player\n",
        "    if player_is_winner(temp_board):\n",
        "      return i\n",
        "    for j in moves:\n",
        "      temp_board=board.copy()\n",
        "      temp_board[j] = opponent\n",
        "      if opponent_is_winner(temp_board):\n",
        "        return j\n",
        "  # TO TEST RUN TEST CASES\n",
        "  return random.choice(moves)\n",
        "  # TODO: INSERT CODE ABOVE\n",
        "  return worst_move_for_opponent\n",
        "\n",
        "\n",
        "eval(agent2, random_agent)\n",
        "eval(random_agent, agent2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dk__w7ZERwCj",
        "outputId": "a4f53910-8a25-48ba-cbf3-2da135a48818"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wins:\n",
            " x: 87\n",
            " o: 3\n",
            " c: 10\n",
            "wins:\n",
            " x: 13\n",
            " o: 52\n",
            " c: 35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#How to submit your project:\n",
        "\n",
        "1. Please change the name of the project to *your name, project 1*:\n",
        "  * for example:  \n",
        "    *  Taylan Sen, Project 1.ipynb\n",
        "1. Download the file as a ipynb file. Then upload it to canvas.\n",
        "\n",
        "Please remember, you can discuss the project amongst yourselves, but you must not copy and paste nor directly copy code from each other."
      ],
      "metadata": {
        "id": "juE2CRdvVyBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "J0F-nAOGWbM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here is some test code I used that you are welcom to repurpose\n",
        "\n",
        "def test_is_x_winner():\n",
        "  assert(is_x_winner(['X']*9))\n",
        "  assert(not is_x_winner(['O']*9))\n",
        "  assert(is_x_winner(['X', 'X', 'X', 'O','O','O','-','-','O']))\n",
        "  assert(not is_x_winner(['X', 'X', 'O', 'O','O','O','-','-','O']))\n",
        "\n",
        "def test_is_game_over():\n",
        "  assert(is_game_over(['X']*9) == 'X')\n",
        "  assert(is_game_over(['O']*9) == 'O')\n",
        "  assert(is_game_over(['-']*9) == False)\n",
        "  assert(is_game_over(['X', 'X', 'X', 'O','O','O','-','-','O']) == 'X')\n",
        "  assert(is_game_over(['X', 'X', 'O', 'O','O','O','-','-','O']) == 'O')\n",
        "  assert(is_game_over(['X', 'O', 'O',   'O','X','X',  'X','O','O']) == 'CAT')\n",
        "  assert(is_game_over(['X', 'X', 'O',   '-','O','O',  'X','O','X']) == False)\n",
        "\n",
        "test_is_x_winner()\n",
        "test_is_game_over()\n",
        "\n"
      ],
      "metadata": {
        "id": "o0gxX9G0UOhb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "6b15b56b-0be4-471a-d7d6-b406d1b2e722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f533700c2c50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_game_over\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'X'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'O'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'O'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'X'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'O'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtest_is_x_winner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mtest_is_game_over\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-f533700c2c50>\u001b[0m in \u001b[0;36mtest_is_x_winner\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_is_x_winner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_x_winner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mis_x_winner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'O'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_x_winner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'X'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'X'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'O'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'O'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'O'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'is_x_winner' is not defined"
          ]
        }
      ]
    }
  ]
}